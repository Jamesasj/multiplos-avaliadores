install.packages('bnlearn')
library(bnlearn)
library(bnlearn)
install.packages('bnlearn')
library(bnlearn)
data(marathontimes)
install.packages('LearnBayes')
data(studentdata)
data(studentdata)
library(LearnBayes)
data(studentdata)
View(studentdata)
texto <- c("O novo software funcionou bem, mas ninguém ficou feliz",
"Há um trem na plataforma A. Há outro train na plataforma B")
texto <- c("O novo software funcionou bem, mas ninguém ficou feliz",
"Há um trem na plataforma A. Há outro train na plataforma B")
texto2 <- c("Há um trem na plataforma A. Há outro train na plataforma B")
texto <- c("O novo software funcionou bem, mas ninguém ficou feliz")
texto2 <- c("Há um trem na plataforma A. Há outro train na plataforma B")
library(tidyr)
library(dplyr)
library(tidytext)
texto <- data_frame(texto = c("O novo software funcionou bem, mas ninguém ficou feliz"))
texto <- data_frame(texto = c("O novo software funcionou bem, mas ninguém ficou feliz"))
texto2 <- data_frame(texto = c("Há um trem na plataforma A. Há outro train na plataforma B"))
texto <- data_frame(documento = c(1), texto = c("O novo software funcionou bem, mas ninguém ficou feliz"))
texto2 <- data_frame(documento = c(1),texto = c("Há um trem na plataforma A. Há outro train na plataforma B"))
tokens <- texto %>% unnest_tokens(palavras, texto )
View(tokens)
texto1 <- data_frame(documento = c(1), texto = c("O novo software funcionou bem, mas ninguém ficou feliz"))
texto2 <- data_frame(documento = c(1),texto = c("Há um trem na plataforma A. Há outro train na plataforma B"))
tokens <- texto %>% unnest_tokens(palavras, texto )
split(texto1$texto, "mas", drop = FALSE)
split(texto1$texto, " mas ", drop = FALSE)
strsplit(texto1$texto, " mas ")
tokens <- texto %>% unnest_tokens(palavras, texto )
resultado <- strsplit(texto1$texto, " mas ")
View(resultado)
fruits <- c(
"apples and oranges and pears and bananas",
"pineapples and mangos and guavas"
)
str_split(fruits, " and ")
install.packages('tidyverse')
library(tidyr)
library(dplyr)
library(tidytext)
library(tidyverse)
install.packages('tidyverse')
install.packages("tidyverse")
library(tidyr)
library(dplyr)
library(tidytext)
library(tidyverse)
fruits <- c(
"apples and oranges and pears and bananas",
"pineapples and mangos and guavas"
)
str_split(fruits, " and ")
str_split(fruits, " and ")[[1]]
View(str_split(fruits, " and "))
str_split(fruits, " and ")
str_split(fruits, " and ")[[1]]
str_split(fruits, " and ")[[1]][1]
resultado[[1]]
resultado[[1]][1]
texto1 <- data_frame(documento = c(1), texto = c("O novo software funcionou bem, mas ninguém ficou feliz"))
texto2 <- data_frame(documento = c(1),texto = c("Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(texto1$texto, "mas")
resultado[[1]][1]
texto1 %>% separate(texto, c("mas"))
x <- c("abcdef", "ghifjk")
str_sub(x, 3, 3)
x <- c("abcdef", "ghifjk")
str_sub(x, 3, 5)
texto1 <- data_frame(documento = c(1),
texto = c("O novo software funcionou bem, mas ninguém ficou feliz"))
texto2 <- data_frame(documento = c(1),
texto = c("Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(texto1$texto, "mas")
View(resultado)
texto1 <- data_frame(documento = c(1),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas"))
texto2 <- data_frame(documento = c(1),
texto = c("Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(texto1$texto, "mas")
dados <- data_frame(documento = c(1),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas")
dados %>% separate(texto, c("mas"))
tokens <- dados %>% unnest_tokens(palavras, texto)
View(tokens)
View(resultado)
resultado <- strsplit(dados$texto, "mas")
View(dados)
View(resultado)
gsub("([ab])", "\\1_\\1_", "abc and ABC")
tokens <- dados %>% unnest_tokens(palavras, texto)
View(tokens)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas",
"Há um trem na plataforma A. Há outro train na plataforma B"))
tokens <- dados %>% unnest_tokens(palavras, texto)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas.
agora com salto de linhas",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas")
tokens <- dados %>% unnest_tokens(palavras, texto)
View(tokens)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas.",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas")
tokens <- dados %>% unnest_tokens(palavras, texto)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas.",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas")
View(resultado)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas essse resulta",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas")
View(resultado)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas essse resulta",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas")
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou felizmas essse resulta",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas")
View(resultado)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou feliz essse resulta",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas ")
View(resultado)
tokens <- dados %>% unnest_tokens(palavras, texto,token =  "characters")
View(tokens)
tokens <- dados %>% unnest_tokens(palavras, texto,token =  "lines")
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou feliz essse resulta",
"Há um trem na plataforma A.
Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas ")
tokens <- dados %>% unnest_tokens(palavras, texto,token =  "lines")
tokens <- dados %>% unnest_tokens(palavras, texto,token =  "sentences")
View(tokens)
dados <- data_frame(documento = c(1,2),
texto = c("O novo software funcionou bem, mas ninguém ficou feliz essse resulta",
"Há um trem na plataforma A. Há outro train na plataforma B"))
resultado <- strsplit(dados$texto, "mas ")
tokens <- dados %>% unnest_tokens(palavras, texto,token =  "sentences")
View(tokens)
tokens <- dados %>% unnest_tokens(palavras, texto,token =  "sentences")
View(tokens)
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
tokens <- dados %>% unnest_tokens(palavras, texto,token =  "sentences")
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>% unnest_tokens(sentencas, texto,token =  "sentences")
a2 <- a1
unnest(setNames(strsplit(a1$sentencas, ','), a1$sentencas), Description) %>% unique()
strsplit(a1$sentencas, ',')
setNames(strsplit(a1$sentencas, ','), a1$documento)
unnest(setNames(strsplit(a1$sentencas, ','), a1$documento), documento)
library(tidyr)
library(dplyr)
library(tidytext)
unnest(setNames(strsplit(a1$sentencas, ','), a1$documento), documento) %>% unique()
setNames(strsplit(a1$sentencas, ','), a1$documento), documento)
setNames(strsplit(a1$sentencas, ','), a1$documento)
unnest(setNames(strsplit(a1$sentencas, ','), a1$documento), sentencas)
dados <- setNames(strsplit(a1$sentencas, ','), a1$documento)
dados <- setNames(strsplit(a1$sentencas, ','), a1$documento)
View(dados)
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>% unnest_tokens(sentencas, texto,token =  "sentences")
a2 <- a1 %>% unnest_tokens(sentencas, sentencas, token = )
dados2 <- setNames(strsplit(a1$sentencas, ','), a1$documento)
View(dados2)
df <- tibble(
x = 1:3,
y = c("a", "d,e,f", "g,h")
)
View(df)
df %>%
transform(y = strsplit(y, ",")) %>%
unnest(y)
a2 <- a1 %>% transform(sentencas = strsplit(sentencas,",")) %>% unnest(sentences)
a1 %>% transform(sentencas = strsplit(sentencas,","))
View(a1 %>% transform(sentencas = strsplit(sentencas,",")))
a2 <- a1 %>% transform(sentencas = strsplit(sentencas,",")) %>% unnest(sentencas)
View(a2)
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>% unnest_tokens(sentencas, texto,token =  "sentences") #separar sentenças por segmento
a2 <- a1 %>% transform(sentencas = strsplit(sentencas,";")) %>% unnest(sentencas) # separa por ponto-vigula
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>% unnest_tokens(sentencas, texto,token =  "sentences") #separar sentenças por segmento
a2 <- a1 %>% transform(sentencas = strsplit(sentencas,";")) %>% unnest(sentencas) # separa por ponto-vigula
library(tidyr)
library(dplyr)
library(tidytext)
library(tidyverse)
#Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies.
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>% unnest_tokens(sentencas, texto,token =  "sentences") #separar sentenças por segmento
a2 <- a1 %>% transform(sentencas = strsplit(sentencas,";")) %>% unnest(sentencas) # separa por ponto-vigula
View(a2)
a3 <- a2 %>% transform(sentencas = strsplit(sentencas,":")) %>% unnest(sentencas) # separa por dois-pontos
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>% unnest_tokens(sentencas, texto,token =  "sentences") #separar sentenças por segmento
a2 <- a1 %>% transform(sentencas = strsplit(sentencas,";")) %>% unnest(sentencas) # separa por ponto-vigula
a3 <- a2 %>% transform(sentencas = strsplit(sentencas,":")) %>% unnest(sentencas) # separa por dois-pontos
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york: Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>% unnest_tokens(sentencas, texto,token =  "sentences") #separar sentenças por segmento
a2 <- a1 %>% transform(sentencas = strsplit(sentencas,";")) %>% unnest(sentencas) # separa por ponto-vigula
a3 <- a2 %>% transform(sentencas = strsplit(sentencas,":")) %>% unnest(sentencas) # separa por dois-pontos
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>%
unnest_tokens(sentencas, texto,token =  "sentences") #separar sentenças por segmento
a2 <- a1 %>%
transform(sentencas = strsplit(sentencas,";")) %>%
unnest(sentencas) # separa por ponto-vigula
a3 <- a2 %>%
transform(sentencas = strsplit(sentencas,":")) %>%
unnest(sentencas) # separa por dois-pontos
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,",")) %>%
unnest(sentencas) # separa por vigula*
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>%
unnest_tokens(sentencas, texto,token =  "sentences", to_lower = FALSE) #separar sentenças por segmento
a2 <- a1 %>%
transform(sentencas = strsplit(sentencas,";")) %>%
unnest(sentencas) # separa por ponto-vigula
a3 <- a2 %>%
transform(sentencas = strsplit(sentencas,":")) %>%
unnest(sentencas) # separa por dois-pontos
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,",")) %>%
unnest(sentencas) # separa por vigula*
View(a4)
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou modifica locução prepositiva
library(tidyr)
library(dplyr)
library(tidytext)
library(tidyverse)
#Three new issues began trading on the new york Stok Exchage today, : and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies.
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>%
unnest_tokens(sentencas, texto,token =  "sentences", to_lower = FALSE) #separar sentenças por segmento
a2 <- a1 %>%
transform(sentencas = strsplit(sentencas,";")) %>%
unnest(sentencas) # separa por ponto-vigula
a3 <- a2 %>%
transform(sentencas = strsplit(sentencas,":")) %>%
unnest(sentencas) # separa por dois-pontos
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but", "(?=.(on)*?),"))) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but", "/(?=.(on)*?),/"))) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but" , "(?=.(on)*?)," ))) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,"(?=.(on)*?)," )) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,"(?=.(on)*?)," , perl = TRUE)) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
View(a4)
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
transform(sentencas = strsplit(sentencas, "(?=.(on)*?)," , split = TRUE)) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
transform(sentencas = strsplit(sentencas, "(?=.(on)*?)," , perl = TRUE)) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but")))
a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
transform(sentencas = strsplit(sentencas, "(?=.(on)*?)," , perl = TRUE))
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) %>%
transform(sentencas = strsplit(sentencas, "(?=.(on)*?)," , perl = TRUE)) %>%
unnest(sentencas)
View(a4)
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) %>%
transform(sentencas = strsplit(sentencas, "(?=\s(On)\s.*?)," , perl = TRUE)) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
library(tidyr)
library(dplyr)
library(tidytext)
library(tidyverse)
#Three new issues began trading on the new york Stok Exchage today, : and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies.
dados <- data_frame(documento = c(1),
texto = c("Three new issues began trading on the new york Stok Exchage today, and one began trading on the Nasdaq/National Makdet System last week. On the Big Board, Crawford & CO., Altlanta, (CFD) began trading today. Crawford evaluates health care plans, manages medical and disabality aspects of worker's compensation injuries and is involved in claims adjustmentes for insurance companies."))
a1 <- dados %>%
unnest_tokens(sentencas, texto,token =  "sentences", to_lower = FALSE) #separar sentenças por segmento
a2 <- a1 %>%
transform(sentencas = strsplit(sentencas,";")) %>%
unnest(sentencas) # separa por ponto-vigula
a3 <- a2 %>%
transform(sentencas = strsplit(sentencas,":")) %>%
unnest(sentencas) # separa por dois-pontos
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) %>%
transform(sentencas = strsplit(sentencas, "(?=\s(On)\s.*?)," , perl = TRUE)) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a4 <- a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) %>%
transform(sentencas = strsplit(sentencas, "(?=\s(On)\s.*?),")) %>%
unnest(sentencas) # separa por vigula que marca uma sentença, proposição ou **modifica locução** prepositiva
a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) %>%
transform(sentencas = strsplit(sentencas, "(?=\s(On)\s.*?),"))
a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) %>%
transform(sentencas = strsplit(sentencas, "(?=/\s(On)/\s.*?),"))
a3 %>%
transform(sentencas = strsplit(sentencas,c(", and", ", but"))) %>%
unnest(sentencas) %>%
transform(sentencas = strsplit(sentencas, "(?=\\s(On)\\s.*?),"))
install.packages("CRF")
library(CRF)
kappa(x1 <- cbind(1, 1:10)) # 15.71
kappa(x1, exact = TRUE)        # 13.68
kappa(x2 <- cbind(x1, 2:11)) # high! [x2 is singular!]
hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
sv9 <- svd(h9 <- hilbert(9))$ d
kappa(h9)  # pretty high!
kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
kappa(h9, exact = TRUE) / kappa(h9)  # 0.677 (i.e., rel.error = 32%)
kappa(x1 <- cbind(1, 1:10)) # 15.71
kappa(x1, exact = TRUE)        # 13.68
kappa(x2 <- cbind(x1, 2:11)) # high! [x2 is singular!]
hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
sv9 <- svd(h9 <- hilbert(9))$ d
kappa(h9)  # pretty high!
kappa(h9, exact = TRUE) == max(sv9) / min(sv9)
kappa(h9, exact = TRUE) / kappa(h9)  # 0.677 (i.e., rel.error = 32%)
View(x1)
View(x2)
res <- kappa(x1 <- cbind(1, 1:10)) # 15.71
kappa(x2 <- cbind(x1, 2:11)) # high! [x2 is singular!]
View(h9)
kappa(h9)  # pretty high!
res <- kappa.qr(x1 <- cbind(1, 1:10)) # 15.71
res <- kappa.default(x1 <- cbind(1, 1:10)) # 15.71
res <- kappa(x1 <- cbind(50:40, 1:10))
res <- kappa(x1 <- cbind(40:50, 1:10))
res <- kappa(x1 <- cbind(41:50, 1:10))
res <- kappa(x1 <- cbind(1:10, 1:10))
res <- kappa(x1 <- cbind(1, 1:10))
res <- kappa(x1 <- cbind(1:10, 1:10))
res <- kappa(x1 <- t(cbind(1:10, 1:10))) # 15.71
res <- kappa(x1 <- t(cbind(1, 1:10))) # 15.71
install.packages("KappaGUI")
library(KappaGUI)
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
Trait1_A = c(1,0,2,1,1,1,0,2,1,1),
Trait1_B = c(1,2,0,1,2,1,0,1,2,1),
Trait2_A = c(1,4,5,2,3,5,1,2,3,4),
Trait2_B = c(2,5,2,2,4,5,1,3,1,4)
)
scores
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
kappaCohen(scores, weight="unweighted")
kappaCohen(scores, weight="squared")
res <- kappaCohen(scores, weight="unweighted")
View(scores)
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
ProfessorA = c(1,0,2,1,1,1,0,2,1,1),
ProfessorB = c(1,2,0,1,2,1,0,1,2,1),
ProfessorC = c(1,4,5,2,3,5,1,2,3,4),
ProfessorD = c(2,5,2,2,4,5,1,3,1,4)
)
scores
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
res <- kappaCohen(scores, weight="unweighted")
kappaCohen(scores, weight="squared")
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
Professor1A = c(1,0,2,1,1,1,0,2,1,1),
Professor2B = c(1,2,0,1,2,1,0,1,2,1),
Professor1C = c(1,4,5,2,3,5,1,2,3,4),
Professor2D = c(2,5,2,2,4,5,1,3,1,4)
)
scores
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
res <- kappaCohen(scores, weight="unweighted")
kappaCohen(scores, weight="squared")
library(KappaGUI)
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
Professor1_A = c(1,0,2,1,1,1,0,2,1,1),
Professor1_B = c(1,2,0,1,2,1,0,1,2,1),
Professor2_A = c(1,4,5,2,3,5,1,2,3,4),
Professor2_B = c(2,5,2,2,4,5,1,3,1,4)
)
scores
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
res <- kappaCohen(scores, weight="unweighted")
kappaCohen(scores, weight="squared")
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
Professor1_A = c(1,0,2,1,1,1,0,2,1,1),
Professor2_A = c(1,4,5,2,3,5,1,2,3,4)
)
scores
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
res <- kappaCohen(scores, weight="unweighted")
kappaCohen(scores, weight="squared")
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
Professor1_A = c(1,4,5,2,3,5,1,2,3,4),
Professor2_A = c(1,4,5,2,3,5,1,2,3,4)
)
scores
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
res <- kappaCohen(scores, weight="unweighted")
kappaCohen(scores, weight="squared")
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
Professor1_A = c(1,4,5,2,3,5,1,2,3,4),
Professor2_A = c(1,4,5,2,3,0,1,2,3,4)
)
scores
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
res <- kappaCohen(scores, weight="unweighted")
kappaCohen(scores, weight="squared")
# Here we create and display an artifical dataset,
# describing two traits coded by two raters:
scores <- data.frame(
Professor1_A = c(1,4,5,2,3,5,1,2,3,4),
Professor2_A = c(1,4,5,2,3,0,1,2,3,4),
Professor3_A = c(1,4,5,2,3,5,1,2,3,4)
)
# Retrieve Cohen's kappa for Trait1 and Trait2,
# to evaluate inter-rater agreement between raters A and B:
res <- kappaCohen(scores, weight="unweighted")
setwd("C:\\PROJETOS\\avaliacao_pares_professor")
lista_doc <- c("professor1.csv", "professor2.csv")
dados.df.notas <- data.frame(arquivo = as.character(), notas = as.data.frame())
for (documento in lista_doc) {
dado <- read.csv(documento)
novo <- data.frame(arquivo = documento, notas = dados)
dados.df.notas = rbind(dados.df.notas)
}
dados.df.notas <- data.frame(arquivo = as.character(), notas = as.data.frame())
for (documento in lista_doc) {
dados <- read.csv(documento)
novo <- data.frame(arquivo = documento, notas = dados)
dados.df.notas = rbind(dados.df.notas)
}
dados.df.notas <- data.frame(arquivo = as.character(), notas = as.data.frame())
for (documento in lista_doc) {
dados <- read.csv(documento)
novo <- data.frame(arquivo = documento, notas = dados)
dados.df.notas = rbind(dados.df.notas, novo)
}
dados.df.notas <- data.frame(arquivo = as.character(), notas = as.data.frame())
for (documento in lista_doc) {
